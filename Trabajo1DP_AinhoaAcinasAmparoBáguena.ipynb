{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1173be5b-c4e1-42bf-9532-f8d49cbc40ed",
   "metadata": {},
   "source": [
    "## Trabalho Parte 1 - Alunas: Ainhoa Acinas Amparo Báguena"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b2c59c3-9f64-42f5-a0f8-1e38cca16b7c",
   "metadata": {},
   "source": [
    "### INTRODUÇÃO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53337fc8-dd40-4a1b-8189-e0f8c16895ad",
   "metadata": {},
   "source": [
    "Este trabalho consiste em avaliar e classificar a qualidade de automóveis utilizando um conjunto de dados específico (“Car Evaluation Data Set”). Os dados podem ser descarregados a partir da seguinte ligação: https://drive.google.com/file/d/1RfFy8n53YqRDMCrVq5wEDEGGkqWMAPSb/view?usp=drive_link.\n",
    "O objetivo é construir um modelo que, com base em caraterísticas como o preço de compra, preço de manutenção, número de portas, capacidade de passageiros, tamanho da bagageira e segurança estimada, determine a qualidade de um carro em quatro categorias possíveis: `unacc` (inaceitável), `acc` (aceitável), `good` (bom), e `vgood` (muito bom).\n",
    "Vários modelos de aprendizagem automática serão implementados e comparados para escolher o modelo mais eficaz para esta tarefa de classificação"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bf078cd-e380-40c8-b0a9-5916fbccab37",
   "metadata": {},
   "source": [
    "### Leitura de dados"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9303b61f-1081-4565-818a-8ea8acad31a8",
   "metadata": {},
   "source": [
    "Em primeiro lugar, importamos as bibliotecas que vamos utilizar para realizar o nosso projeto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ab01a81d-1230-44de-9a9e-af722d44942b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%matplotlib inline \n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "from sklearn import tree\n",
    "from sklearn.svm import SVC\n",
    "from sklearn import naive_bayes\n",
    "from scipy.optimize import minimize\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "from sklearn.neighbors import RadiusNeighborsClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neighbors import NearestCentroid"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dd4cf5a-470b-4e3a-9f0e-d06d71b2c6e2",
   "metadata": {},
   "source": [
    "Agora vamos carregar os dados do ficheiro com que vamos trabalhar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "14b201f3-9af6-4fcc-9973-b1bbe922f8cb",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>buying</th>\n",
       "      <th>maint</th>\n",
       "      <th>doors</th>\n",
       "      <th>persons</th>\n",
       "      <th>lug_boot</th>\n",
       "      <th>safety</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>vhigh</td>\n",
       "      <td>vhigh</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>small</td>\n",
       "      <td>low</td>\n",
       "      <td>unacc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>vhigh</td>\n",
       "      <td>vhigh</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>small</td>\n",
       "      <td>med</td>\n",
       "      <td>unacc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>vhigh</td>\n",
       "      <td>vhigh</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>small</td>\n",
       "      <td>high</td>\n",
       "      <td>unacc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>vhigh</td>\n",
       "      <td>vhigh</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>med</td>\n",
       "      <td>low</td>\n",
       "      <td>unacc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>vhigh</td>\n",
       "      <td>vhigh</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>med</td>\n",
       "      <td>med</td>\n",
       "      <td>unacc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1723</th>\n",
       "      <td>low</td>\n",
       "      <td>low</td>\n",
       "      <td>5more</td>\n",
       "      <td>more</td>\n",
       "      <td>med</td>\n",
       "      <td>med</td>\n",
       "      <td>good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1724</th>\n",
       "      <td>low</td>\n",
       "      <td>low</td>\n",
       "      <td>5more</td>\n",
       "      <td>more</td>\n",
       "      <td>med</td>\n",
       "      <td>high</td>\n",
       "      <td>vgood</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1725</th>\n",
       "      <td>low</td>\n",
       "      <td>low</td>\n",
       "      <td>5more</td>\n",
       "      <td>more</td>\n",
       "      <td>big</td>\n",
       "      <td>low</td>\n",
       "      <td>unacc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1726</th>\n",
       "      <td>low</td>\n",
       "      <td>low</td>\n",
       "      <td>5more</td>\n",
       "      <td>more</td>\n",
       "      <td>big</td>\n",
       "      <td>med</td>\n",
       "      <td>good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1727</th>\n",
       "      <td>low</td>\n",
       "      <td>low</td>\n",
       "      <td>5more</td>\n",
       "      <td>more</td>\n",
       "      <td>big</td>\n",
       "      <td>high</td>\n",
       "      <td>vgood</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1728 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     buying  maint  doors persons lug_boot safety  class\n",
       "0     vhigh  vhigh      2       2    small    low  unacc\n",
       "1     vhigh  vhigh      2       2    small    med  unacc\n",
       "2     vhigh  vhigh      2       2    small   high  unacc\n",
       "3     vhigh  vhigh      2       2      med    low  unacc\n",
       "4     vhigh  vhigh      2       2      med    med  unacc\n",
       "...     ...    ...    ...     ...      ...    ...    ...\n",
       "1723    low    low  5more    more      med    med   good\n",
       "1724    low    low  5more    more      med   high  vgood\n",
       "1725    low    low  5more    more      big    low  unacc\n",
       "1726    low    low  5more    more      big    med   good\n",
       "1727    low    low  5more    more      big   high  vgood\n",
       "\n",
       "[1728 rows x 7 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nombres_columnas = [\"buying\", \"maint\", \"doors\", \"persons\", \"lug_boot\", \"safety\",\"class\"]\n",
    "df = pd.read_csv('car.data', delimiter=',', header=None, names=nombres_columnas)\n",
    "df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cf6a0fc-fd55-4302-bd2f-b92b23ab2d8d",
   "metadata": {},
   "source": [
    "Convertemos todas as colunas em valores numéricos para podermos aplicar os modelos. Além disso, separamos os 6 atributos que vão fazer parte do X do que vai fazer parte do y, que será a variável a ser prevista."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "589f6f76-e6ff-4ab2-bfde-67c53394221b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>buying</th>\n",
       "      <th>maint</th>\n",
       "      <th>doors</th>\n",
       "      <th>persons</th>\n",
       "      <th>lug_boot</th>\n",
       "      <th>safety</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1723</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1724</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1725</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1726</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1727</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1728 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      buying  maint  doors  persons  lug_boot  safety\n",
       "0          3      3      0        0         2       1\n",
       "1          3      3      0        0         2       2\n",
       "2          3      3      0        0         2       0\n",
       "3          3      3      0        0         1       1\n",
       "4          3      3      0        0         1       2\n",
       "...      ...    ...    ...      ...       ...     ...\n",
       "1723       1      1      3        2         1       2\n",
       "1724       1      1      3        2         1       0\n",
       "1725       1      1      3        2         0       1\n",
       "1726       1      1      3        2         0       2\n",
       "1727       1      1      3        2         0       0\n",
       "\n",
       "[1728 rows x 6 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for column in df.columns:\n",
    "    if df[column].dtype == 'object':\n",
    "        df[column] = LabelEncoder().fit_transform(df[column])\n",
    "X = df.iloc[:, :-1]\n",
    "y = df.iloc[:, -1]\n",
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88c027f8-1729-417b-825d-332f8198cb30",
   "metadata": {},
   "source": [
    "Separamos os dados do nosso ficheiro em dois conjuntos, treino e validação, para podermos escolher mais tarde o nosso melhor modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "32384d40-a2fc-4888-9cb7-5ebc29f8fdf6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "Xtrain,Xtest,ytrain,ytest = train_test_split(X,y,test_size=0.3,random_state=123)\n",
    "Xtrain, Xval, ytrain, yval = train_test_split(Xtrain, ytrain, test_size = 0.3, random_state = 123)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ef9444a-ee64-440d-b2e9-b8761c0e354f",
   "metadata": {},
   "source": [
    "### Análise  do modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e4a37e6-5be1-4e15-9f10-8cb92020bcd7",
   "metadata": {},
   "source": [
    "Em primeiro lugar, vamos criar um dicionário no qual vamos armazenar as melhores combinações de parâmetros que obtemos de cada modelo, bem como as suas precisões na validação."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9f53421f-78d6-4a04-845b-b658df418246",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "best_params={}\n",
    "best_accs={}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d101142-911a-4736-82a9-715278c41aa1",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Regressão logística"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d7de01c-13dc-4828-b366-fec28b8c20fb",
   "metadata": {},
   "source": [
    "Em primeiro lugar, vamos utilizar o modelo de regressão logística. Para o fazer, vamos treinar o modelo com a classe LogisticRegression do scikit-learn e utilizar o método 'newton-cg' para encontrar o mínimo. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cd1c56b0-8ba5-4e1d-b8d2-06f8ce49ef1a",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precisão no conjunto de treino: 0.6843971631205674\n",
      "Precisão no conjunto de validação: 0.6639118457300276\n"
     ]
    }
   ],
   "source": [
    "LogReg = LogisticRegression(penalty ='l2', C = 10.0e50, max_iter = 400, solver = 'newton-cg')\n",
    "LogReg = LogReg.fit(Xtrain, ytrain.ravel())\n",
    "\n",
    "ypredtrain = LogReg.predict(Xtrain).reshape(-1, 1)\n",
    "acctrain = accuracy_score(ypredtrain, ytrain)\n",
    "\n",
    "ypredval = LogReg.predict(Xval).reshape(-1, 1)\n",
    "accval = accuracy_score(ypredval, yval)\n",
    "\n",
    "print(\"Precisão no conjunto de treino: {}\".format(acctrain))\n",
    "print(\"Precisão no conjunto de validação: {}\".format(accval))\n",
    "\n",
    "best_accs['Regresión Logística'] = accval"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82123c58-c3b3-4f2c-8ce6-646bb45d6b11",
   "metadata": {},
   "source": [
    "Verificamos que a precisão nos conjuntos de treino e de validação não é muito elevada. Por isso, vamos experimentar a regressão logística com regularização para ver se melhora um pouco a precisão."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e3cbec8-7cf2-4d70-be32-c61280bc7321",
   "metadata": {},
   "source": [
    "#### Regressão logística com regularização"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21a689b7-e0ad-41a5-a59c-f9bb65533f63",
   "metadata": {},
   "source": [
    "Em segundo lugar, utilizaremos este método com regularização.\n",
    "\n",
    "Em primeiro lugar, aplicaremos as transformações necessárias aos dados para classificar corretamente os dados correspondentes à malha do plano.\n",
    "\n",
    "Posteriormente, utilizaremos a biblioteca scikit-learn para treinar o modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d94898f1-2180-4e5e-a537-81d9cda48d56",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "poly = PolynomialFeatures(4)\n",
    "Xpoly_train = poly.fit_transform(Xtrain)\n",
    "Xpoly_val = poly.transform(Xval)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "Xpoly_norm_train = scaler.fit_transform(Xpoly_train)\n",
    "Xpoly_norm_val = scaler.transform(Xpoly_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e48c6b27-b4c5-4cc6-b490-e87b9790f325",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precisão no conjunto de treino: [1.0, 0.9964539007092199, 0.8132387706855791]\n",
      "Precisão no conjunto de validação: [0.9421487603305785, 0.9338842975206612, 0.790633608815427]\n"
     ]
    }
   ],
   "source": [
    "accstrain = []\n",
    "accsval = []\n",
    "valores_C=[np.inf, 1, 1/100] \n",
    "\n",
    "for i, valor_lambda in enumerate(valores_C):\n",
    "    LogRegu = LogisticRegression(penalty = 'l2', C = valor_lambda, max_iter = 500, solver = 'newton-cg')\n",
    "    LogRegu = LogRegu.fit(Xpoly_norm_train, ytrain.ravel())\n",
    "   \n",
    "    ypredtrain = LogRegu.predict(Xpoly_norm_train).reshape(-1, 1)\n",
    "    ypredval = LogRegu.predict(Xpoly_norm_val).reshape(-1, 1)\n",
    "    \n",
    "    accstrain.append(accuracy_score(ypredtrain, ytrain))\n",
    "    accsval.append(accuracy_score(ypredval, yval))\n",
    "\n",
    "print(\"Precisão no conjunto de treino: {}\".format(accstrain))\n",
    "print(\"Precisão no conjunto de validação: {}\".format(accsval))\n",
    "\n",
    "best_accs['Regresión Logística con Regularización'] = np.max(accsval)\n",
    "best_params['Regresión Logística con Regularización'] = valores_C[np.argmax(accsval)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6048259-70e8-4f22-99c4-6f4c4b65df7a",
   "metadata": {},
   "source": [
    "#### KNN e classificação"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6fa2d70-320a-4370-93d6-0117c1c1cf25",
   "metadata": {
    "tags": []
   },
   "source": [
    "Agora vamos aplicar o algoritmo KNN disponível no Scikit-Learn. No KNN, classificamos um novo exemplo tendo em conta os k exemplos mais próximos. Em vez de o utilizarmos com um k selecionado a priori, vamos experimentar com diferentes k e manteremos aquele que nos der o melhor resultado.\n",
    "\n",
    "Esta implementação encontra-se no pacote neighbours e a sua classe específica é KNeighborsClassifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9db90e14-bf3e-4d36-b378-b11ffc8d7bf9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Precisão no conjunto de treino com k=1: 1.0\n",
      "Precisão no conjunto de validação com k=1: 0.7603305785123967\n",
      "\n",
      "Precisão no conjunto de treino com k=2: 0.8711583924349882\n",
      "Precisão no conjunto de validação com k=2: 0.7245179063360881\n",
      "\n",
      "Precisão no conjunto de treino com k=3: 0.9349881796690307\n",
      "Precisão no conjunto de validação com k=3: 0.8539944903581267\n",
      "\n",
      "Precisão no conjunto de treino com k=4: 0.9231678486997635\n",
      "Precisão no conjunto de validação com k=4: 0.8292011019283747\n",
      "\n",
      "Precisão no conjunto de treino com k=5: 0.9373522458628841\n",
      "Precisão no conjunto de validação com k=5: 0.8815426997245179\n",
      "\n",
      "Precisão no conjunto de treino com k=6: 0.9302600472813238\n",
      "Precisão no conjunto de validação com k=6: 0.859504132231405\n",
      "\n",
      "Precisão no conjunto de treino com k=7: 0.9243498817966903\n",
      "Precisão no conjunto de validação com k=7: 0.8677685950413223\n",
      "\n",
      "Precisão no conjunto de treino com k=8: 0.9160756501182034\n",
      "Precisão no conjunto de validação com k=8: 0.8650137741046832\n",
      "\n",
      "Precisão no conjunto de treino com k=9: 0.8983451536643026\n",
      "Precisão no conjunto de validação com k=9: 0.8457300275482094\n",
      "\n",
      "Precisão no conjunto de treino com k=10: 0.8936170212765957\n",
      "Precisão no conjunto de validação com k=10: 0.8292011019283747\n",
      "\n",
      "Precisão no conjunto de treino com k=11: 0.8794326241134752\n",
      "Precisão no conjunto de validação com k=11: 0.8099173553719008\n",
      "\n",
      "Precisão no conjunto de treino com k=12: 0.8687943262411347\n",
      "Precisão no conjunto de validação com k=12: 0.790633608815427\n",
      "\n",
      "O melhor valor para k é  5, com uma precisão no conjunto de validação de 0.8815426997245179\n"
     ]
    }
   ],
   "source": [
    "vals_acc_test_ponderado = np.zeros(12)\n",
    "accmax = 0\n",
    "kmax = 0\n",
    "for k in range(12):\n",
    "    knn_clasif = KNeighborsClassifier(n_neighbors = k+1)\n",
    "    knn_clasif.fit(Xtrain, ytrain)\n",
    "    ypredtrain = knn_clasif.predict(Xtrain)\n",
    "    ypredval = knn_clasif.predict(Xval)\n",
    "    acctrain = accuracy_score(ypredtrain, ytrain)\n",
    "    accval = accuracy_score(ypredval, yval)\n",
    "    print(\"\\nPrecisão no conjunto de treino com k={}: {}\".format(k+1, acctrain))\n",
    "    print(\"Precisão no conjunto de validação com k={}: {}\".format(k+1, accval))\n",
    "    \n",
    "    if accval > accmax:\n",
    "        accmax = accval\n",
    "        kmax = k+1\n",
    "    \n",
    "print('\\nO melhor valor para k é  {}, com uma precisão no conjunto de validação de {}'.format(kmax, accmax))\n",
    "\n",
    "best_accs['KNN'] = accmax\n",
    "best_params['KNN'] = kmax"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee0fec45-6044-4be3-81b4-8625f0d09cdd",
   "metadata": {
    "tags": []
   },
   "source": [
    "Utilizaremos então k = 5 vizinhos. Passamos a comparar diferentes métricas no nosso algoritmo.\n",
    "\n",
    "Para comparação, utilizaremos as seguintes distâncias:\n",
    "* Distância de Manhattan\n",
    "* Distância Euclidiana\n",
    "* Distância de Minkowski com p = 1,5\n",
    "* Semelhança de cosseno (disponível com a métrica='cosine'): $$d_c(\\mathbf{x}, \\mathbf{y}) = \\frac{\\mathbf{x}\\cdot \\mathbf{y}}{\\Vert \\mathbf{x}\\Vert \\Vert \\mathbf{y} \\Vert }$$ \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f8d63ac9-8c7c-43ed-9ec7-6bd18152f270",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Classificador KNeighborsClassifier(metric='manhattan'). \n",
      "Precisão no conjunto de treino: 0.9397163120567376. Precisão no conjunto de validação: 0.8677685950413223\n",
      "\n",
      "Classificador KNeighborsClassifier(metric='euclidean'). \n",
      "Precisão no conjunto de treino: 0.9373522458628841. Precisão no conjunto de validação: 0.8815426997245179\n",
      "\n",
      "Classificador KNeighborsClassifier(p=1.5). \n",
      "Precisão no conjunto de treino: 0.9373522458628841. Precisão no conjunto de validação: 0.8705234159779615\n",
      "\n",
      "Classificador KNeighborsClassifier(metric='cosine'). \n",
      "Precisão no conjunto de treino: 0.9078014184397163. Precisão no conjunto de validação: 0.8292011019283747\n",
      "\n",
      "O melhor classificador é: KNeighborsClassifier(metric='euclidean'), com uma precisão no conjunto de validação de : 0.8815426997245179\n"
     ]
    }
   ],
   "source": [
    "# Debemos guardar el accuracy de test en acc_test\n",
    "clasif1 = KNeighborsClassifier(n_neighbors = 5, metric = 'manhattan')\n",
    "clasif2 = KNeighborsClassifier(n_neighbors = 5, metric = 'euclidean')\n",
    "clasif3 = KNeighborsClassifier(n_neighbors = 5, p = 1.5)\n",
    "clasif4 = KNeighborsClassifier(n_neighbors = 5, metric = 'cosine')\n",
    "\n",
    "clasificadores = [clasif1, clasif2, clasif3, clasif4]\n",
    "acc = []\n",
    "\n",
    "for clasificador in clasificadores:\n",
    "    clasificador.fit(Xtrain, ytrain)\n",
    "    \n",
    "    ypredval = clasificador.predict(Xval)\n",
    "    accval = accuracy_score(ypredval, yval)\n",
    "    acc.append(accval)\n",
    "    \n",
    "    ypredtrain = clasificador.predict(Xtrain)\n",
    "    acctrain = accuracy_score(ypredtrain, ytrain)\n",
    "    \n",
    "    print('\\nClassificador {}. \\nPrecisão no conjunto de treino: {}. Precisão no conjunto de validação: {}'.format(clasificador, acctrain, accval))\n",
    "\n",
    "mejorAcc = np.max(acc)\n",
    "mejorClasif = clasificadores[acc.index(mejorAcc)]\n",
    "\n",
    "mejorClasif.fit(Xtrain, ytrain)\n",
    "\n",
    "ypredtrain = mejorClasif.predict(Xtrain)\n",
    "ypredval = mejorClasif.predict(Xval)\n",
    "\n",
    "acctrain = accuracy_score(ypredtrain,ytrain)\n",
    "accval = accuracy_score(ypredval,yval)\n",
    "\n",
    "print('\\nO melhor classificador é: {}, com uma precisão no conjunto de validação de : {}'.format(mejorClasif, accval))\n",
    "\n",
    "best_accs['KNN distancias'] = accval\n",
    "best_params['KNN distancias'] = mejorClasif"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b760a989-0a61-4edc-9fd6-c170226fce6f",
   "metadata": {},
   "source": [
    "Como mostra o código, o melhor classificador é o que utiliza a distância euclidiana e que nos dá a melhor precisão no conjunto de validação até agora."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f10b3440-419d-4678-981c-29cf9ece5730",
   "metadata": {},
   "source": [
    "#### Naïve Bayes classificação"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18690ded-166d-47a2-a5ea-966d40982d7a",
   "metadata": {},
   "source": [
    "De seguida, utilizaremos o algoritmo Naïve Bayes, que prevê a classe da instância de teste com a maior probabilidade.\n",
    "\n",
    "Decidimos testar com este algoritmo devido à sua rapidez em treinar os dados e classificá-los."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "155b627d-4e74-46fa-8c79-9a20636af32b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precisão no conjunto de treino: 0.5981087470449172\n",
      "Precisão no conjunto de validação: 0.581267217630854\n"
     ]
    }
   ],
   "source": [
    "NaiveBayes = naive_bayes.GaussianNB()\n",
    "NaiveBayes=NaiveBayes.fit(Xtrain,ytrain)\n",
    "\n",
    "ypredtrain = NaiveBayes.predict(Xtrain)\n",
    "acctrain = accuracy_score(ypredtrain, ytrain)\n",
    "\n",
    "ypredval = NaiveBayes.predict(Xval)\n",
    "accval = accuracy_score(ypredval, yval)\n",
    "\n",
    "print(\"Precisão no conjunto de treino: {}\".format(acctrain))\n",
    "print(\"Precisão no conjunto de validação: {}\".format(accval))\n",
    "best_accs['Naive Bayes']=accval"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc5a4199-b8c4-4c64-b2c9-683da87b4320",
   "metadata": {},
   "source": [
    "Observamos que, para este modelo, obtemos uma precisão no conjunto de validação de 58,13%, o que é bastante baixo em comparação com os modelos anteriores. Por conseguinte, podemos concluir que este método não é muito adequado para o nosso conjunto de dados."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4839bb74-6d9c-49c0-a637-92f08ecbfa12",
   "metadata": {},
   "source": [
    "#### Redes Neurais"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b04b5a89-f4f2-488f-8f48-dfd4970bd1b0",
   "metadata": {},
   "source": [
    "Neste ponto, vamos testar os algoritmos de *Redes Neurais*, que são algoritmos que tentam imitar o cérebro humano. \n",
    "\n",
    "Primeiro, como vimos na teoria, para trabalhar com problemas multi-classe com redes neurais precisamos transformar a saída que é um único valor (a classe) em um vetor de 0s e 1s, onde o 1 na posição correspondente nos diz a qual classe o exemplo pertence. Isto é necessário porque vamos ter um neurónio de saída para cada uma das classes. Para conseguir esta transformação, vamos utilizar o método *OneHotEncoder do Scikit-Learn*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "11dea729-0988-47ad-b31d-27499d374bea",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(846, 4)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ainho\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Instancia un objeto de tipo OneHotEncoder, con sparse=False\n",
    "y_train_reshaped = np.array(ytrain).reshape(-1, 1)\n",
    "\n",
    "# Instancia el OneHotEncoder\n",
    "encoder = OneHotEncoder(sparse=False)\n",
    "\n",
    "# Aplica fit_transform a y_train_reshaped\n",
    "y_onehot = encoder.fit_transform(y_train_reshaped)\n",
    "print(y_onehot.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f9171a6-9c97-42f0-9969-8cfafa54a89d",
   "metadata": {},
   "source": [
    "A primeira coisa que precisamos de fazer é implementar a função de custo para avaliar o custo para um determinado conjunto de parâmetros. Para isso, precisamos primeiro de aplicar a propagação para a frente, que nos dá o resultado para cada exemplo de entrada. Para isso, começaremos por implementar a função sigmoide."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9b20374d-1cd3-4cff-9ec0-490024145bfe",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def sigmoid(z):\n",
    "    z = 1/(1 + np.exp(-z))\n",
    "    return z"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa083721-ed0f-4b8f-8d5a-f36a39fc5613",
   "metadata": {},
   "source": [
    "De seguida, calculamos a propagação para a frente, tal como aprendemos na teoria e na prática."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d45acef1-2e77-49b0-9bc8-5a62d1b00dfe",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def forward_propagate(X, theta1, theta2):\n",
    "    m = X.shape[0]\n",
    "    \n",
    "    # Añadimos la columna de unos a X para obtener a1\n",
    "    a1 = np.hstack((np.ones(m).reshape(-1, 1), X))\n",
    "    \n",
    "    # Calculamos z2 \n",
    "    # Por otro lado, theta1 tiene tantas filas como neuronas en la capa oculta y columnas como atributos + 1\n",
    "    z2 = np.dot(a1, theta1.T)\n",
    "    \n",
    "    # Añadimos la columna de unos a la sigmoide de z2 (que es a2) para obtener el a2 definitivo\n",
    "    a2 = sigmoid(z2)\n",
    "    unos = np.ones((a2.shape[0], 1))\n",
    "    a2 = np.hstack((unos, a2))\n",
    "\n",
    "    # Calculamos z3\n",
    "    z3 = np.dot(a2, theta2.T)\n",
    "    \n",
    "    # Obtenemos la salida final en h\n",
    "    h = sigmoid(z3)\n",
    "    \n",
    "    return a1, z2, a2, z3, h"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f17de3a-1e15-482d-bbaf-d003a79a3934",
   "metadata": {},
   "source": [
    "Com a propagação para a frente, podemos agora calcular a função de custo. No entanto, antes de a calcular, preparamos outras funções que serão necessárias mais tarde."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "efa3904b-d2b0-4c5b-8637-d0a92e1a9fb7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((10, 7), (4, 11))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Configuración inicial\n",
    "input_size = 6\n",
    "hidden_size = 10\n",
    "num_labels = 4\n",
    "np.random.seed(123456789)\n",
    "\n",
    "# Inicializamos los parámetros de la red aleatoriamente\n",
    "# El tamaño del array es el tamaño de las dos matrices de pesos concatenadas\n",
    "params = (np.random.random(size = hidden_size * (input_size + 1) + num_labels * (hidden_size + 1)) - 0.5) * 0.25\n",
    "\n",
    "# Podemos desempaquetar los parámetros que acabamos de inicializar igual que lo hacemos en la función de coste\n",
    "theta1 = np.matrix(np.reshape(params[:hidden_size * (input_size + 1)], (hidden_size, (input_size + 1))))\n",
    "theta2 = np.matrix(np.reshape(params[hidden_size * (input_size + 1):], (num_labels, (hidden_size + 1))))\n",
    "\n",
    "# Vemos los tamaños de las matrices theta1 y theta2\n",
    "theta1.shape, theta2.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bf9fa10-60cf-4016-9da6-71f59f7e2b3f",
   "metadata": {},
   "source": [
    "Verificamos se o que foi implementado até agora está a funcionar corretamente. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cf0da8bc-de81-454c-b297-8025da64799f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "a1, z2, a2, z3, h = forward_propagate(Xtrain, theta1, theta2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f77ded92-679a-4927-b583-33a93d1cbd69",
   "metadata": {},
   "source": [
    "Em seguida, implementamos o algoritmo de retropropagação para reduzir o erro no conjunto de treino, calculando a atualização dos parâmetros. Em primeiro lugar, precisamos de calcular o gradiente da função sigmoide que implementámos anteriormente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1c7dea11-0322-4635-a397-41e954022e01",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def sigmoid_gradient(z):\n",
    "    z = sigmoid(z)*(1 - sigmoid(z))\n",
    "    return z"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93f59e30-639d-4e95-899f-559a03e37712",
   "metadata": {},
   "source": [
    "Implementamos agora a propagação para trás para calcular os gradientes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "42eb94bf-97e4-4cab-b604-997db0adc961",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def backprop(params, input_size, hidden_size, num_labels, X, y):\n",
    "    # Lo primero que debemos hacer es una progagación hacia adelante y calcular el coste\n",
    "    # Para ello, puedes copiar el código de la función implementada para calcular el coste (sin regularización)\n",
    "    # desempaquetamos las matrices con los parámetros para cada capa\n",
    "    theta1 = np.reshape(params[:hidden_size * (input_size + 1)], (hidden_size, (input_size + 1)))\n",
    "    theta2 = np.reshape(params[hidden_size * (input_size + 1):], (num_labels, (hidden_size + 1)))\n",
    "    \n",
    "    # Ejecutamos las propagación hacia adelante para obtener las salidas para cada ejemplo\n",
    "    a1, z2, a2, z3, h = forward_propagate(X, theta1, theta2)\n",
    "    \n",
    "    # Calculamos el coste\n",
    "    m = X.shape[0]\n",
    "    J = 1/m * np.sum(-y * np.log(h) - (1 - y) * np.log(1 - h))\n",
    "    \n",
    "    # A partir de aquí comienza la implementación de backpropagation\n",
    "    \n",
    "    # Inicializamos los acumuladores delta1  y delta2 a ceros, con las dismensiones de los theta1 y theta2\n",
    "    delta1 = np.zeros(theta1.shape)\n",
    "    delta2 = np.zeros(theta2.shape)\n",
    "    \n",
    "    # Aunque podríamos vectorizarlo, vamos a hacerlo para cada ejemplo\n",
    "    for t in range(m):\n",
    "        # Obtenemos lo que necesitamos del ejemplo t (cálculos obtenidos en la propagación hacia adelante)\n",
    "        # Para usar las fórmulas tal y como aparecen en teoría, vamos a coger todos los vectores en forma de columna (reshape(-1,1))\n",
    "        a1t = a1[t,:].reshape(-1, 1) \n",
    "        z2t = z2[t,:].reshape(-1, 1) \n",
    "        a2t = a2[t,:].reshape(-1, 1)\n",
    "        ht = h[t,:].reshape(-1, 1)  \n",
    "        yt = y[t,:].reshape(-1, 1)  \n",
    "        \n",
    "        # Calculamos el error en la capa de salida (delta3), almacenar en d3t\n",
    "        d3t = ht - yt \n",
    "        \n",
    "        # Para calcular el error en la capa oculta (delta2) necesitamos añadir un uno al inicio del vector z2\n",
    "        z2t = np.vstack((np.array([1]), z2t))\n",
    "        \n",
    "        # Calculamos d2 a partir del error de la capa de salida, los parámetros en theta2 y el gradiente de z2t\n",
    "        d2t = np.dot(theta2.T, d3t) * sigmoid_gradient(z2t)\n",
    "        \n",
    "        # Ya podemos calcular los gradientes a partir de los errores\n",
    "        # Para calcular el gradiente de los theta1, tenemos en cuenta el error en la capa oculta d2t\n",
    "        # Ten en cuenta que habrá que no necesitamos el primer elemento de d2t.\n",
    "        # Se debe acumular el gradiente en delta1 y delta2\n",
    "        delta1 = delta1 + d2t[1:] * a1t.T\n",
    "        delta2 = delta2 + d3t * a2t.T \n",
    "    \n",
    "    # Calculamos el gradiente finalmente dividiendo entre el número de ejemplos\n",
    "    delta1 = delta1 / m\n",
    "    delta2 = delta2 / m\n",
    "    \n",
    "    # Para pasar los gradientes a minimize los ponemos en un vector\n",
    "    grad = np.concatenate((np.ravel(delta1), np.ravel(delta2)))\n",
    "    \n",
    "    return J, grad\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d8b23784-6a76-44d4-8455-ebeb2b1c90b6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "O custo obtido: 2.805747308593745\n"
     ]
    }
   ],
   "source": [
    "J, grad = backprop(params, input_size, hidden_size, num_labels, Xtrain, y_onehot)\n",
    "print('O custo obtido: ' + str(J))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a96a7d2-7299-47e7-9b96-8ab0047e74cc",
   "metadata": {},
   "source": [
    "Depois de criar estas funções e de as testar, podemos agora treinar a rede e utilizá-la para fazer previsões. Utilizamos o método  *minimize*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5a150404-30c2-4a29-9e9e-b5eb3a878502",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ainho\\AppData\\Local\\Temp\\ipykernel_9224\\3614032905.py:2: OptimizeWarning: Unknown solver options: maxiter\n",
      "  fmin = minimize(fun = backprop, x0 = params, args = (input_size, hidden_size, num_labels, Xtrain, y_onehot),\n",
      "C:\\Users\\ainho\\AppData\\Local\\Temp\\ipykernel_9224\\3499779148.py:13: RuntimeWarning: divide by zero encountered in log\n",
      "  J = 1/m * np.sum(-y * np.log(h) - (1 - y) * np.log(1 - h))\n",
      "C:\\Users\\ainho\\AppData\\Local\\Temp\\ipykernel_9224\\3499779148.py:13: RuntimeWarning: invalid value encountered in multiply\n",
      "  J = 1/m * np.sum(-y * np.log(h) - (1 - y) * np.log(1 - h))\n"
     ]
    }
   ],
   "source": [
    "# Minimizar la función objetivo que acabamos de definir\n",
    "fmin = minimize(fun = backprop, x0 = params, args = (input_size, hidden_size, num_labels, Xtrain, y_onehot), \n",
    "                method = 'TNC', jac = True, options = {'maxiter': 250})\n",
    "#fmin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "364cc935-6076-4b4e-ab8f-6ad92e89a2af",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Desempaquetamos los parámetros obtenidos como resultado del entrenamiento almacenados en fmin.x\n",
    "# Crea las variables theta1 y theta2\n",
    "theta1 = np.reshape(fmin.x[:hidden_size * (input_size + 1)], (hidden_size, (input_size + 1)))\n",
    "theta2 = np.reshape(fmin.x[hidden_size * (input_size + 1):], (num_labels, (hidden_size + 1)))\n",
    "    \n",
    "# Utilizamos los parámetros desempaquetados con la propagación hacia adelante para obtener la predicción para nuestros ejemplos\n",
    "a1, z2, a2, z3, h = forward_propagate(Xval, theta1, theta2)\n",
    "\n",
    "# Finalmente, para obtener la clase para cada ejemplo, buscamos de las diez salidas cuál es la más alta\n",
    "# y usamos su índice como valor predicho (utilizar np.argmax con el el valor adecuado para el parámetro axis).\n",
    "ypred = np.argmax(h, axis=1).reshape(-1,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e49215cb-f13b-4915-86c5-f31b7b9dc7bb",
   "metadata": {},
   "source": [
    "Por fim, calculamos a precisão do modelo em treino para verificar o seu desempenho."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d27280db-3610-4e22-83a5-c3960accdaa3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precisão no conjunto de validação: 0.8429752066115702\n"
     ]
    }
   ],
   "source": [
    "# Calcula el accuracy en los datos de entrenamiento\n",
    "accval = accuracy_score(ypred, yval)\n",
    "print(\"Precisão no conjunto de validação: {}\".format(accval))\n",
    "\n",
    "best_accs['Redes Neuronales'] = accval"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cecee5b-6c76-4e3c-8a9c-04f013610456",
   "metadata": {},
   "source": [
    "Por fim, testamos vários valores dos diferentes parâmetros utilizados pelo modelo para obter a melhor combinação, de modo a obter a maior precisão no conjunto de validação."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4d113d4b-2499-4a34-8852-24e8a0dab8f0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ainho\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\ainho\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\ainho\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\ainho\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\ainho\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Os melhores hiperparâmetros são: 500 iterações, ((100, 100),) neurónios em cada camada oculta e (0.1,) como o valor de alfa.\n",
      "A precisão dos dados de validação é de: 0.9752066115702479\n"
     ]
    }
   ],
   "source": [
    "#Listas de parámetros a explorar\n",
    "hidden_layer_sizes_options = [(50,25), (100,50), (100,100)]\n",
    "alpha_options = [0.01, 0.1, 1.0]\n",
    "max_iter_options = [500, 750, 1000]\n",
    "\n",
    "best_params_combination = {}\n",
    "best_accval = 0.0\n",
    "\n",
    "for hidden_layer_sizes in hidden_layer_sizes_options:\n",
    "        for alpha in alpha_options:\n",
    "            for max_iter in max_iter_options:\n",
    "                modelo = MLPClassifier(hidden_layer_sizes = hidden_layer_sizes,\n",
    "                                       activation = 'relu',\n",
    "                                       alpha = alpha,\n",
    "                                       max_iter = max_iter,\n",
    "                                       random_state = 42\n",
    "                                      )\n",
    "                modelo.fit(Xtrain, ytrain.ravel())\n",
    "                ypred = modelo.predict(Xval)\n",
    "                accval = accuracy_score(ypred, yval)\n",
    "                if accval > best_accval:\n",
    "                    best_accval = accval\n",
    "                    best_hidden_layer = hidden_layer_sizes,\n",
    "                    best_alpha = alpha,\n",
    "                    best_max_iter = max_iter\n",
    "                best_params_combination ['best_hidden_layer'] = best_hidden_layer  \n",
    "                best_params_combination ['best_alpha'] = best_alpha  \n",
    "                best_params_combination ['best_max_iter'] = best_max_iter \n",
    "                \n",
    "print('Os melhores hiperparâmetros são: {} iterações, {} neurónios em cada camada oculta e {} como o valor de alfa.' .format(best_max_iter, best_hidden_layer, best_alpha))\n",
    "print('A precisão dos dados de validação é de: {}'.format(best_accval))\n",
    "\n",
    "best_accs['Red Neuronal Multicapa'] = best_accval\n",
    "best_params['Red Neuronal Multicapa'] = best_params_combination"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b5131bf-2072-40d8-9746-a26a618af3a4",
   "metadata": {
    "tags": []
   },
   "source": [
    "Concluímos a partir destes resultados que, por enquanto, o modelo de rede neural é o melhor, uma vez que obtemos uma melhor precisão do que com os modelos anteriores. Mesmo assim, vamos tentar outro."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ea51bf9b-893d-4337-a590-f9cb3ff26a31",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'best_hidden_layer': ((100, 100),),\n",
       " 'best_alpha': (0.1,),\n",
       " 'best_max_iter': 500}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_params_combination"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17f5158f-3995-4d61-81f3-798243f24279",
   "metadata": {},
   "source": [
    "#### SVMs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9939b39-badd-41a3-9f50-4347a76e3c6a",
   "metadata": {},
   "source": [
    "Agora, vamos utilizar os algoritmos SVM para treinar o conjunto de dados e prever a precisão. Para tal, vamos testar com várias combinações de parâmetros qual delas tem a melhor precisão de validação. Aprendemos, portanto, várias SVMs com todas as combinações de valores C e gama e escolhemos a que tem o menor erro de validação. Realizamos este processo de afinação de hiper-parâmetros diretamente com a função *GridSearchCV()*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6e9730f4-f02b-4030-b547-0a07691c9716",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precisão no conjunto de treino: 0.9810874704491725\n",
      "Precisão no conjunto de validação: 0.9393939393939394\n"
     ]
    }
   ],
   "source": [
    "C_values = [0.01, 0.1, 1, 10]\n",
    "gamma_values = [0.01, 0.1, 1, 10]\n",
    "kernel= ['rbf', 'linear']\n",
    "\n",
    "# Creamos el diccionario de parámetros a optimizar con los valores de C y gamma de las listas\n",
    "param_grid = {'kernel': kernel, 'C': C_values, 'gamma': gamma_values}\n",
    "\n",
    "# Haz la llamada a la función GridSearchCV con un clasificador SVC, el diccionario de parámetros definido y 3 particiones\n",
    "clasificador = SVC()\n",
    "clasificadores = GridSearchCV(clasificador, param_grid, scoring = 'accuracy', cv = 3)\n",
    "\n",
    "# Entrenamos los modelos \n",
    "clasificadores.fit(Xtrain, ytrain)\n",
    "\n",
    "# Creamos un modelo SVC con los mejores parámetros obenidos\n",
    "svc_best_params = SVC(kernel = clasificadores.best_params_['kernel'], gamma = clasificadores.best_params_['gamma'], C = clasificadores.best_params_['C'])\n",
    "\n",
    "# Entrenamos la SVM con los datos de train\n",
    "svc_best_params.fit(Xtrain, ytrain)\n",
    "\n",
    "# Obtenemos el accuracy en train y validación\n",
    "acctrain = svc_best_params.score(Xtrain, ytrain)\n",
    "accval = svc_best_params.score(Xval, yval)\n",
    "\n",
    "print(\"Precisão no conjunto de treino: {}\".format(acctrain))\n",
    "print(\"Precisão no conjunto de validação: {}\".format(accval))\n",
    "\n",
    "best_accs['SVMs'] = accval\n",
    "best_params['SVMs'] = clasificadores.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1aa5293-df65-4ebb-9a3c-f641b7d16d9e",
   "metadata": {},
   "source": [
    "### ÁRVORES DE DECISÃO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "388eff27-5c66-419c-b44e-171941af1ba6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parâmetros selecionados:  {'ccp_alpha': 0.0001, 'criterion': 'entropy', 'min_samples_leaf': 1, 'min_samples_split': 2}\n"
     ]
    }
   ],
   "source": [
    "# ARBOL DE DECISION\n",
    "arbol=DecisionTreeClassifier(random_state=123)\n",
    "\n",
    "criterio=['gini','entropy']\n",
    "min_samples_split=[2,5,10]\n",
    "min_samples_leaf=[1,2,4]\n",
    "ccp_alpha=[0.0001, 0.001,0.002,0.003]\n",
    "\n",
    "param_grid = {'criterion': criterio, 'min_samples_split': min_samples_split, 'min_samples_leaf':min_samples_leaf, 'ccp_alpha':ccp_alpha}\n",
    "\n",
    "arbol = GridSearchCV(DecisionTreeClassifier(), param_grid)\n",
    "arbol.fit(Xtrain,ytrain.ravel())\n",
    "mejores_parametros=arbol.best_params_\n",
    "print(\"Parâmetros selecionados: \", mejores_parametros)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c05b7917-c737-4df9-baf4-09bc635cd0c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precisão no conjunto de treino: 1.0\n",
      "Precisão no conjunto de validação: 0.977961432506887\n"
     ]
    }
   ],
   "source": [
    "acc_train=arbol.score(Xtrain,ytrain)\n",
    "acc_val=arbol.score(Xval,yval)\n",
    "print(\"Precisão no conjunto de treino: {}\".format(acc_train))\n",
    "print(\"Precisão no conjunto de validação: {}\".format(acc_val))\n",
    "\n",
    "best_accs['ArbolDecision'] = accval\n",
    "best_params['ArbolDecision'] = clasificadores.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8616be9f-62de-402d-9da3-b890afaecaef",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "4f0bf321-46f8-4852-a6a3-4e775094c53c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ainho\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\ainho\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\ainho\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\ainho\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\ainho\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\ainho\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\ainho\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\ainho\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\ainho\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\ainho\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\ainho\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\ainho\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\ainho\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\ainho\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\ainho\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\ainho\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\ainho\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\ainho\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\ainho\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\ainho\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\ainho\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\ainho\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\ainho\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\ainho\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\ainho\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\ainho\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\ainho\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\ainho\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\ainho\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\ainho\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\ainho\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\ainho\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\ainho\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\ainho\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\ainho\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\ainho\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\ainho\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\ainho\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\ainho\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\ainho\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\ainho\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\ainho\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\ainho\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\ainho\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\ainho\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\ainho\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\ainho\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\ainho\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\ainho\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\ainho\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\ainho\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\ainho\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\ainho\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\ainho\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\ainho\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\ainho\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\ainho\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\ainho\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\ainho\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\ainho\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\ainho\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\ainho\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\ainho\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\ainho\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\ainho\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\ainho\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\ainho\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\ainho\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\ainho\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\ainho\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\ainho\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\ainho\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\ainho\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\ainho\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\ainho\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\ainho\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\ainho\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\ainho\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\ainho\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\ainho\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\ainho\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\ainho\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\ainho\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\ainho\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\ainho\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\ainho\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\ainho\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\ainho\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\ainho\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\ainho\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\ainho\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\ainho\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\ainho\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\ainho\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\ainho\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\ainho\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\ainho\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\ainho\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\ainho\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\ainho\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\ainho\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\ainho\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\ainho\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\ainho\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\ainho\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\ainho\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\ainho\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\ainho\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\ainho\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\ainho\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\ainho\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\ainho\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\ainho\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\ainho\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\ainho\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\ainho\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\ainho\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\ainho\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\ainho\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\ainho\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parâmetros selecionados:  {'criterion': 'entropy', 'max_features': 'sqrt', 'min_samples_split': 2, 'n_estimators': 300}\n"
     ]
    }
   ],
   "source": [
    "criterio=['gini','entropy']\n",
    "max_features =['auto', 'sqrt', 'log2']\n",
    "min_samples_split=[2,5,10]\n",
    "n_estimators = [50, 100, 200, 300]\n",
    "\n",
    "param_grid = {'criterion': criterio, 'max_features': max_features, 'min_samples_split': min_samples_split, 'n_estimators':n_estimators}\n",
    "\n",
    "arbol = GridSearchCV(RandomForestClassifier(), param_grid)\n",
    "arbol.fit(Xtrain,ytrain.ravel())\n",
    "mejores_parametros=arbol.best_params_\n",
    "print(\"Parâmetros selecionados: \",mejores_parametros)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "5b93c096-a24c-48db-9a4c-8484c211ab1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precisão no conjunto de treino:  1.0\n",
      "Precisão no conjunto de validação:  0.9338842975206612\n"
     ]
    }
   ],
   "source": [
    "RandomForest = RandomForestClassifier(criterion = mejores_parametros['criterion'], max_features =mejores_parametros['max_features'], min_samples_split=mejores_parametros['min_samples_split'], n_estimators=mejores_parametros['n_estimators'])\n",
    "rf = RandomForest.fit(Xtrain, ytrain)\n",
    "\n",
    "pred_train = rf.predict(Xtrain)\n",
    "\n",
    "pred_val = rf.predict(Xval)\n",
    "\n",
    "acc_train=rf.score(Xtrain,ytrain)\n",
    "print(\"Precisão no conjunto de treino: \",acc_train)\n",
    "\n",
    "acc_val=rf.score(Xval,yval)\n",
    "print(\"Precisão no conjunto de validação: \",acc_val)\n",
    "\n",
    "\n",
    "best_accs['Random Forest'] = accval\n",
    "best_params['Random Forest'] = clasificadores.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1900093-229a-4e34-8d67-9ee69ff77a67",
   "metadata": {},
   "source": [
    "### Modelo escolhido"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65a45c34-d99a-4f9f-a6fb-fdb708af99cd",
   "metadata": {
    "tags": []
   },
   "source": [
    "Escolheremos o melhor modelo utilizando os dicionários em que armazenámos os diferentes classificadores e as respectivas precisões na validação. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "df387cca-4561-4c38-8691-2afa31c21146",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Regresión Logística': 0.6639118457300276,\n",
       " 'Regresión Logística con Regularización': 0.9421487603305785,\n",
       " 'KNN': 0.8815426997245179,\n",
       " 'KNN distancias': 0.8815426997245179,\n",
       " 'Naive Bayes': 0.581267217630854,\n",
       " 'Redes Neuronales': 0.8429752066115702,\n",
       " 'Red Neuronal Multicapa': 0.9752066115702479,\n",
       " 'SVMs': 0.9393939393939394,\n",
       " 'ArbolDecision': 0.9393939393939394,\n",
       " 'Random Forest': 0.9393939393939394}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_accs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "6b4ebd86-c470-4c8b-ba27-09e261aebb64",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "O melhor classificador é  Red Neuronal Multicapa, com precisão no conjunto de validação 0.9752066115702479\n"
     ]
    }
   ],
   "source": [
    "# Obtener una lista con todos los valores\n",
    "lista_de_valores = list(best_accs.values())\n",
    "\n",
    "#Obtenemos el mejor accuracy de entre todos los que hemos ido obteniendp\n",
    "mejorAcc = np.max(lista_de_valores)\n",
    "\n",
    "#Obtenemos cuál es el clasificador que proporciona ese accuracy\n",
    "mejorClasif = None\n",
    "for clave, valor in best_accs.items():\n",
    "    if valor == mejorAcc:\n",
    "        mejorClasif = clave\n",
    "        break\n",
    "\n",
    "print('\\nO melhor classificador é  {}, com precisão no conjunto de validação {}'.format(mejorClasif, mejorAcc))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca435c0c-27f9-4eef-a662-2e5477601533",
   "metadata": {},
   "source": [
    "Vamos agora utilizar o melhor modelo (árvore de decisão como modelo de seleção de variáveis) para prever os dados do nosso conjunto de teste e obter a precisão correspondente. Para o fazer, começamos por ler os dados de teste. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d6fb877d-1efb-4982-a9b9-e87956739ed2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'best_hidden_layer': ((100, 100),),\n",
       " 'best_alpha': (0.1,),\n",
       " 'best_max_iter': 500}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mejores_parametros = best_params['Red Neuronal Multicapa']\n",
    "mejores_parametros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "7ad75155-1c95-4fc5-bf65-98a6c7c815e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "\n",
    "# Selección de características utilizando SelectKBest\n",
    "selector = SelectKBest(score_func=f_classif, k='all')  # Cambia 'all' a un número específico si lo deseas\n",
    "X_train_selected = selector.fit_transform(Xtrain, ytrain)\n",
    "\n",
    "# Ahora puedes entrenar tu modelo con las características seleccionadas\n",
    "modeloRNM = MLPClassifier(\n",
    "    hidden_layer_sizes=(100,100),\n",
    "    activation='relu',\n",
    "    alpha=0.1,\n",
    "    max_iter=500,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "RNM = modeloRNM.fit(X_train_selected, ytrain.ravel())\n",
    "\n",
    "# Para transformar el conjunto de prueba\n",
    "X_test_selected = selector.transform(Xtest)\n",
    "ypredTest = RNM.predict(X_test_selected)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "22378bbd-f7f6-48b4-a017-59c00a357455",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9710982658959537"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(ypredTest, ytest)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e878fe14-c920-429d-8fcb-ba8a87c4445d",
   "metadata": {},
   "source": [
    "### Conclusões"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50b5ab2a-33e9-4757-8fd3-9d282a9b96eb",
   "metadata": {},
   "source": [
    "Neste processo de seleção de modelos, avaliámos diferentes técnicas de aprendizagem automática, cada uma com as suas próprias caraterísticas. Após análise, o modelo *Red Neuronal Multicapa* destacou-se pelo seu desempenho e exatidão, com uma exatidão de 97% na validação. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
